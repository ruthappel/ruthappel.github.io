---
---

@article{Appel2023a,
abstract = {Social media companies have come under increasing pressure to remove misinformation from their platforms, but partisan disagreements over what should be removed have stymied efforts to deal with misinformation in the United States. Current explanations for these disagreements center on the “fact gap”—differences in perceptions about what is misinformation. We argue that partisan differences could also be due to “party promotion”—a desire to leave misinformation online that promotes one's own party—or a “preference gap”—differences in internalized preferences about whether misinformation should be removed. Through an experiment where respondents are shown false headlines aligned with their own or the opposing party, we find some evidence of party promotion among Democrats and strong evidence of a preference gap between Democrats and Republicans. Even when Republicans agree that content is false, they are half as likely as Democrats to say that the content should be removed and more than twice as likely to consider removal as censorship.},
author = {Appel, Ruth E. and Pan, Jennifer and Roberts, Margaret E.},
doi = {10.1126/sciadv.adg6799},
html = {https://doi.org/10.1126/sciadv.adg6799},
journal = {Science Advances},
number = {44},
pages = {1--10},
title = {{Partisan conflict over content moderation is more than disagreement about facts}},
volume = {9},
year = {2023},
selected = {true}
}

@incollection{Matz2022,
author = {Matz, Sandra C. and Appel, Ruth E. and Croll, Brian},
booktitle = {The psychology of technology: Social science research in the age of Big Data},
doi = {10.1037/0000290-012},
html = {https://doi.org/10.1037/0000290-012},
editor = {Matz, Sandra C.},
pages = {379--420},
publisher = {American Psychological Association},
title = {{Privacy and ethics in the age of Big Data}},
abstract = {This chapter discusses the new ethical challenges introduced by the age of Big Data. Although there are many other ethical challenges related to technology and data (e.g., addiction, inequality), it reviews the topic of privacy as one of the major challenges associated with Big Data. The chapter introduces the concept of privacy, briefly discussing its history, universality, and core assumptions that lie at the heart of privacy protections. It then moves on to the questions of how Big Data threatens our privacy in unprecedented ways and challenges current approaches to privacy protection. Next, the chapter discusses how placing the burden of privacy protection on users alone is misguided and provide a number of potential systemic solutions related to regulation, collaboration, design principles, and technological tools. It concludes with concrete practical guidelines for researchers and practitioners of how to design studies, products, and services that protect individuals' privacy.},
year = {2022}
}

@incollection{Appel2021,
author = {Appel, Ruth E. and Matz, Sandra C.},
booktitle = {Measuring and Modeling Persons and Situations},
doi = {10.1016/b978-0-12-819200-9.00015-6},
html = {https://doi.org/10.1016/b978-0-12-819200-9.00015-6},
isbn = {9780128192009},
abstract = {Advances in the collection, storage, and processing of large amounts of user data have given rise to psychological targeting, which we define as the process of extracting individuals’ psychological characteristics from their digital footprints in order to target them with psychologically-informed interventions at scale. In this chapter, we introduce a two-stage framework of psychological targeting consisting of (1) psychological profiling and (2) psychologically-informed interventions. We summarize the most important research findings in relation to the two stages and discuss important methodological opportunities and pitfalls. To help researchers make the most of the opportunities, we also provide practical advice on how to deal with some of the potential pitfalls. Finally, we highlight ethical opportunities and challenges and offer some suggestions for addressing these challenges. If done right, psychological targeting has the potential to advance our scientific understanding of human nature and to enhance the well-being of individuals and society at large.},
keywords = {Big Data,Contextual integrity,Digital footprints,Ethics,Methods,Privacy,Psychological profiling,Psychological targeting,Psychologically-informed interventions},
pages = {193--222},
publisher = {Elsevier},
title = {{Psychological targeting in the age of Big Data}},
url = {http://dx.doi.org/10.1016/B978-0-12-819200-9.00015-6},
year = {2021}
}

@article{Matz2020,
abstract = {Psychological targeting describes the practice of extracting people's psychological profiles from their digital footprints (e.g., their Facebook Likes, Tweets or credit card records) in order to influence their attitudes, emotions or behaviors through psychologically-informed interventions at scale. We discuss how the increasingly blurred lines between public and private information, and the continuation of the outdated practices of notice and consent, challenge traditional conceptualizations of privacy in the context of psychological targeting. Drawing on the theory of contextual integrity, we argue that it is time to rethink privacy and move beyond the questions of who collects what data to how the data are being used. Finally, we suggest that regulations of psychological targeting should be accompanied by a mindset that fosters (1) privacy by design to make it easy for individuals to act in line with their privacy goals, as well as (2) disclosure by choice in which individuals can freely decide whether and when they might be willing to forsake their privacy for better service.},
author = {Matz, Sandra C. and Appel, Ruth E. and Kosinski, Michal},
doi = {10.1016/j.copsyc.2019.08.010},
html = {https://doi.org/10.1016/j.copsyc.2019.08.010},
issn = {2352250X},
journal = {Current Opinion in Psychology},
pages = {116--121},
title = {{Privacy in the age of psychological targeting}},
volume = {31},
year = {2020}
}

@workshop{Appelworkshop1,
author = {Ruth E. Appel},
title = {{Generative AI Regulation Can Learn from Social Media Regulation}},
url = {https://doi.org/10.48550/arXiv.2412.11335},
html = {https://doi.org/10.48550/arXiv.2412.11335},
year = {2024}
}

@under_review{Appelunderreview6,
author = {Ruth E. Appel and Young Mie Kim and Jennifer Pan and Yiqing Xu and Daniel Thomas and Hunt Allcott and Pablo Barberá and Taylor Brown and Adriana Crespo-Tenorio and Drew Dimmery and Deen Freelon and Matthew Gentzkow and Andrew M. Guess and Sandra González-Bailón and Shanto Iyengar and David Lazer and Neil Malhotra and Devra Moehler and Ben Nimmo and Brendan Nyhan and Carlos Velasco Rivera and Jaime Settle and Emily Thorson and Rebekah Tromble and Arjun Wilkins and Magdalena Wojcieszak and Beixian Xiong and Chad Kiewiet de Jonge and Annie Franco and Winter Mason and Natalie Jomini Stroud and Joshua A. Tucker},
title = {{How deceptive online networks reached millions in the US 2020 elections}},
year = {2025}
}

@under_review{Appelunderreview5,
author = {Appel, Ruth E. and Roozenbeek, Jon and Rayburn-Reeves, Rebecca and Corbin, Jonathan and Basol, Melisa and Compton, Joshua and {van der Linden}, Sander},
title = {{Psychological inoculation improves resilience to and reduces willingness to share vaccine misinformation}},
url = {https://osf.io/preprints/psyarxiv/ek5pu},
html = {https://osf.io/preprints/psyarxiv/ek5pu},
year = {2025}
}

@under_review{Appelunderreview4,
author = {Pei, Rui and Grayson, Samantha J. and Appel, Ruth E. and Soh, Serena and Garcia, Sydney and Huang, Emily and Jackson, Matthew O. and Harari, Gabriella M. and Zaki, Jamil},
title = {{Bridging the empathy gap: Reducing empathy misperceptions increases social connectedness}},
year = {2025}
}

@under_review{Appelunderreview3,
author = {Ruth E. Appel},
title = {{Generative AI Regulation Can Learn from Social Media Regulation}},
url = {https://doi.org/10.48550/arXiv.2412.11335},
html = {https://doi.org/10.48550/arXiv.2412.11335},
year = {2025}
}

@under_review{Appelunderreview2,
author = {Jillian Fisher and Ruth E. Appel and Chan Young Park and Yujin Potter and Liwei Jiang and Taylor Sorensen and Shangbin Feng and Yulia Tsvetkov and Margaret Roberts and Jennifer Pan and Dawn Song and Yejin Choi },
abstract = {AI systems often exhibit political bias, influencing users' opinions and decision-making. While political neutrality—defined as the absence of bias—is often seen as an ideal solution for fairness and safety, this position paper argues that true political neutrality is neither feasible nor universally desirable due to its subjective nature and the biases inherent in AI training data, algorithms, and user interactions. However, inspired by Joseph Raz's philosophical insight that "neutrality [...] can be a matter of degree" (Raz, 1986), we argue that striving for some neutrality remains essential for promoting balanced AI interactions and mitigating user manipulation. Therefore, we use the term "approximation" of political neutrality to shift the focus from unattainable absolutes to achievable, practical proxies. We propose eight techniques for approximating neutrality across three levels of conceptualizing AI, examining their trade-offs and implementation strategies. In addition, we explore two concrete applications of these approximations to illustrate their practicality. Finally, we assess our framework on current large language models (LLMs) at the output level, providing a demonstration of how it can be evaluated. This work seeks to advance nuanced discussions of political neutrality in AI and promote the development of responsible, aligned language models.},
title = {{Political Neutrality in AI is Impossible — But Here Is How to Approximate It}},
url = {https://ruthappel.github.io/assets/pdf/PN.pdf},
html = {https://ruthappel.github.io/assets/pdf/PN.pdf},
year = {2025}
}

@under_review{Appelunderreview1,
author = {Shayne Longpre and Kevin Klyman and Ruth E. Appel and Sayash Kapoor and Rishi Bommasani and Michelle Sahar and Sean McGregor and Avijit Ghosh and Borhane Blili-Hamelin and Nathan Butters and Alondra Nelson and Dr. Amit Elazari and Andrew Sellars and Casey John Ellis and Dane Sherrets and Dawn Song and Harley Geiger and Ilona Cohen and Lauren McIlvenny and Madhulika Srikumar and Mark M. Jaycox and Markus Anderljung and Nadine Farid Johnson and Nicholas Carlini and Nicolas Miailhe and Nik Marda and Peter Henderson and Rebecca S. Portnoff and Rebecca Weiss and Victoria Westerhoff and Yacine Jernite and Rumman Chowdhury and Percy Liang and Arvind Narayanan},
title = {{In-House Evaluation Is Not Enough. Towards Robust Third-Party Evaluation and Flaw Disclosure for General-Purpose AI}},
year = {2025}
}

@work_in_progress{Appelunpublished3,
author = {Ruth E. Appel and Jennifer Pan and Margaret E. Roberts},
title = {{How partisanship affects preferences for content moderation in large language models}},
year = {2025}
}

@work_in_progress{Appelunpublished1,
author = {Appel, Ruth E. and Athey, Susan and Karlan, Dean and Koutout, Kristine and Luca, Michael and Manjeer, Utsav and Sacher, Szymon and Wernerfelt, Nils},
title = {{Combating misinformation on social media}},
year = {2025}
}

@policy{Appel2024,
author = {Appel, Ruth E.},
month = {mar},
title = {{EU DSA Election Guidelines Input}},
url = {https://ruthappel.github.io/assets/pdf/EU-DSA-Election-Guidelines-Input.pdf},
html = {https://ruthappel.github.io/assets/pdf/EU-DSA-Election-Guidelines-Input.pdf},
year = {2024}
}

@policy{Schaake2020,
author = {Schaake, Marietje and Appel, Ruth E. and Duplichen, Dathan M. and Einstein, Lisa and Elhai, Wren and {Dhafer Muhammad Faishal}, Muhammad and Foryciarz, Agata and Frankenberg, Sydney L. and Friedman, Toni and Huczok, Zoe and Jasper, Kyra and Jablanski, Danielle and King, Jennifer and Kuang, Cindy and Lee, Heajune and Mantha, Shreya and Patil, Vidyangi and Portelance, Gailyn and Stepahn, Adriana and Tamkin, Alex and Vecchiato, Alessandro and Zhang, Eva and Zhao, Jason},
month = {jun},
pages = {1--23},
title = {{Input on the European Commission White Paper "On Artificial Intelligence – A European approach to excellence and trust"}},
url = {https://hai.stanford.edu/sites/default/files/2020-07/HAI{\_}WhitePaper{\_}v4B.pdf},
html = {https://hai.stanford.edu/sites/default/files/2020-07/HAI{\_}WhitePaper{\_}v4B.pdf},
year = {2020}
}

@media{Appel2024c,
author = {Appel, Ruth E.},
journal = {Freedom to Tinker},
month = {nov},
title = {{Strengthening AI Accountability Through Better Third Party Evaluations}},
url = {https://freedom-to-tinker.com/2024/11/25/strengthening-ai-accountability-through-better-third-party-evaluations-part-1/ },
html = {https://freedom-to-tinker.com/2024/11/25/strengthening-ai-accountability-through-better-third-party-evaluations-part-1/ },
year = {2024}
}

@media{Appel2024b,
author = {Appel, Ruth E.},
journal = {HAI},
month = {nov},
title = {{Strengthening AI Accountability Through Better Third Party Evaluations}},
url = {https://hai.stanford.edu/news/strengthening-ai-accountability-through-better-third-party-evaluations},
html = {https://hai.stanford.edu/news/strengthening-ai-accountability-through-better-third-party-evaluations},
year = {2024}
}

@media{Appel2023b,
author = {Appel, Ruth E.},
journal = {The Conversation},
month = {nov},
title = {{It's not just about facts: Democrats and Republicans have sharply different attitudes about removing misinformation from social media}},
url = {https://theconversation.com/its-not-just-about-facts-democrats-and-republicans-have-sharply-different-attitudes-about-removing-misinformation-from-social-media-216809},
html = {https://theconversation.com/its-not-just-about-facts-democrats-and-republicans-have-sharply-different-attitudes-about-removing-misinformation-from-social-media-216809},
year = {2023}
}

@media{Matz2019,
author = {Matz, Sandra C. and Appel, Ruth E. and Kosinski, Michal},
booktitle = {LSE Business Review},
title = {{Rethinking privacy in the age of psychological targeting}},
url = {https://blogs.lse.ac.uk/businessreview/2019/11/21/rethinking-privacy-in-the-age-of-psychological-targeting/},
html = {https://blogs.lse.ac.uk/businessreview/2019/11/21/rethinking-privacy-in-the-age-of-psychological-targeting/},
urldate = {2020-01-06},
year = {2019}
}